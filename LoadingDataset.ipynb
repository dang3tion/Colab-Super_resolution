{"cells":[{"cell_type":"markdown","metadata":{"id":"nro1Ta20yNBQ"},"source":["#Introduce"]},{"cell_type":"markdown","metadata":{"id":"OahgAgoTxnpo"},"source":["This notebook is created for the case using to load the Dataset (DIV2k) with difference key, and preprocessing image:\n","\n","\n","1.   Load the dataset with key.\n","2.   Preprocessing image.\n","3.   Seperate the dataset.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3696,"status":"ok","timestamp":1643102184176,"user":{"displayName":"Dang Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiVIsFWNExnvgea51afsqnnkGntHaDnff4kdeMfQ=s64","userId":"18279381478995573430"},"user_tz":-420},"id":"0pJbwX-QEN5U","outputId":"eb68945f-4b77-4f0e-d77c-4d839953762a"},"outputs":[{"output_type":"stream","name":"stdout","text":["import libary...\n"]}],"source":["print('import libary...')\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","  "]},{"cell_type":"markdown","source":["Load dataset by key and Tensorflow API"],"metadata":{"id":"EmnZlAa39qwf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SjXd0pQAxjPL"},"outputs":[],"source":["def load_dataset(key='div2k',include_validate=True):\n","  print('using tensorflow_datasets to load the dataset','\\nloading dataset...')\n","  if include_validate:\n","    (train_ds, val_ds), metadata = tfds.load(\n","    key,\n","    split=['train','validation'],\n","    with_info=True,\n","    as_supervised=True,\n","   )\n","  else:\n","    (train_ds), metadata = tfds.load(\n","    key,\n","    split=['train'],\n","    with_info=True,\n","    as_supervised=True,\n","    )\n","  print(metadata)\n","  return (train_ds,val_ds),metadata"]},{"cell_type":"markdown","source":["Load dataset from Folder on Drive directory"],"metadata":{"id":"2aBPrjvT9uyG"}},{"cell_type":"code","source":["def Load_dataset_from_directory(path,scale=4):\n","  def process_path(file_path):\n","  # Load the raw data from the file as a string\n","    img = tf.io.read_file(file_path)\n","    img = tf.io.decode_jpeg(img, channels=3)\n","    return img\n","  list_ds = tf.data.Dataset.list_files(path+'/*', shuffle=False)\n","  data_length = len(list_ds)\n","  hr_data = list_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n","  def build_pair_image(data,scale=4):\n","    lr=[]\n","    for img in data.take(len(data)):\n","      lr.append(tf.cast(tf.image.resize(img, [int(img.shape[0]/scale),int(img.shape[1]/scale)],antialias=True, method=tf.image.ResizeMethod.BICUBIC),dtype=tf.int32))\n","    return lr\n","  lr_data = tf.data.Dataset.from_generator(lambda: \n","                              build_pair_image(hr_data),\n","                              output_types=( tf.int32),\n","                              output_shapes=(tf.TensorShape([ None, None, \n","                                         3])))\n","  data = tf.data.Dataset.zip((lr_data,hr_data))\n","  data=data.apply(tf.data.experimental.assert_cardinality(data_length))\n","  return data"],"metadata":{"id":"9byQ4wBEpyFt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Normalize pixel value to [0,1]"],"metadata":{"id":"47Ygqh6i92Mp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQqAcU1aLp2k"},"outputs":[],"source":["def normalize_img(image):\n","  print('Normalizes images: `uint8` -> `float32`')\n","  return tf.cast(image, tf.float32) /255"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gVN6DS_ZL8UE"},"outputs":[],"source":["def configure_performan(ds,BUFFER_SIZE=1000,BATCH_SIZE=16):\n","  ds=ds.repeat()\n","  ds=ds.shuffle(buffer_size=BUFFER_SIZE)\n","  ds=ds.batch(BATCH_SIZE)\n","  ds=ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n","  return ds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XzZ2Ftvlm8b0"},"outputs":[],"source":["def show(image, label,size):\n","  plt.figure(figsize=(len(image.numpy())/size,len(image.numpy()[0])/size))\n","  plt.imshow(image)\n","  plt.title(np.array(label))\n","  plt.axis('on')"]},{"cell_type":"code","source":["def load_image_from_path(path):\n","  image = tf.keras.preprocessing.image.load_img(path)\n","  image = tf.keras.preprocessing.image.img_to_array(image)\n","  image = tf.constant(image)\n","  return tf.cast(image,tf.int32)"],"metadata":{"id":"Wfz2oRgyp2XP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_image_path(path,image):\n","  tf.keras.utils.save_img(\n","    path, image\n","  )"],"metadata":{"id":"cOQJ5muzp5qE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hKYvmYeJ2qEz"},"outputs":[],"source":["def visualize_augmented(original, augmented,type='lr'):\n","  plt.figure(figsize=(len(original.numpy())/80,len(original.numpy()[0])/80))\n","  # fig = plt.figure()\n","  plt.subplot(1,2,1)\n","  plt.title('Original image'+type)\n","  plt.imshow(original)\n","  plt.subplot(1,2,2)\n","  plt.title('Variant image'+type)\n","  plt.imshow(augmented)"]},{"cell_type":"markdown","source":["Preprocessing data before drop to model"],"metadata":{"id":"ddY9_BL1-CNY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RWaMa6FXuaVJ"},"outputs":[],"source":["def augment(lr,hr,with_adjust=False):\n","  #get the same seed to get the same operator to both lr and hr for image when we use randomly\n","  generator= tf.random.get_global_generator()\n","  seed= generator.make_seeds(2)[0]\n","  #mean that change the pixel value by adujst it's factor\n","  if with_adjust==True:\n","    #low resolution augmentation\n","    lr=tf.image.stateless_random_contrast(lr,0.8,1.2,seed)\n","    lr=tf.image.stateless_random_brightness(lr,0.10,seed)\n","    lr=tf.image.stateless_random_saturation(lr,0.8,1.3,seed)\n","    #high resolution augmentation\n","    hr=tf.image.stateless_random_contrast(hr,0.8,1.2,seed)\n","    hr=tf.image.stateless_random_brightness(hr,0.10,seed)\n","    hr=tf.image.stateless_random_saturation(hr,0.8,1.3,seed)\n","  #random rotate and flip\n","  roate_factor=tf.squeeze(generator.uniform([1],minval=1,maxval=5,dtype=tf.dtypes.int32), axis=0)\n","  lr=tf.image.rot90(lr,roate_factor)\n","  lr=tf.image.stateless_random_flip_left_right(lr,seed)\n","  hr=tf.image.rot90(hr,roate_factor)\n","  hr=tf.image.stateless_random_flip_left_right(hr,seed)\n","  return lr,hr"]},{"cell_type":"markdown","source":["Random Crop image"],"metadata":{"id":"qcf4vxL4-GuA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Av-dnsbTJ-hW"},"outputs":[],"source":["def random_crop(lr_img, hr_img, hr_crop_size, scale):\n","    lr_crop_size = hr_crop_size // scale\n","    lr_shape = tf.shape(lr_img)[:2]\n","    lr_top = tf.random.uniform(shape=(), maxval=lr_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n","    lr_left = tf.random.uniform(shape=(), maxval=lr_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n","    hr_top = lr_top * scale\n","    hr_left = lr_left * scale\n","    lr_crop = lr_img[lr_top:lr_top + lr_crop_size, lr_left:lr_left + lr_crop_size]\n","    hr_crop = hr_img[hr_top:hr_top + hr_crop_size, hr_left:hr_left + hr_crop_size]\n","    return lr_crop, hr_crop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DZieOo_UQJBl"},"outputs":[],"source":["# Normalizes RGB images to [-1, 1].\n","def normalize_m11(x):\n","    return x / 127.5 - 1\n","# Normalizes RGB images to [0, 1].\n","def normalize_01(x):\n","    return x / 255.0\n","# Denomalizes RGB images from [-1, 1].\n","def denormalize_m11(x):\n","    return (x + 1) * 127.5"]},{"cell_type":"markdown","source":["Preprocessing Image with Large size (OOM)"],"metadata":{"id":"4xBHIpY5-2tN"}},{"cell_type":"code","source":["import numpy as np\n","from PIL import Image\n","def get_sr_image(model, lr, max_image_dimension=512, patch_size=96, batch_size=16):\n","    lr = lr[np.newaxis]\n","\n","    if max(lr.shape) <= max_image_dimension:\n","        return process_full_image(model, lr)\n","\n","    return process_in_patches(model, lr, patch_size, batch_size)\n","\n","def unpad_patched_scaled_image(lr_image, patches_per_row, patches_per_col, patch_size, padded_scaled_image):\n","    _, lr_rows, lr_cols, _ = lr_image.shape\n","\n","    padded_rows = patches_per_row * patch_size\n","    padded_cols = patches_per_col * patch_size\n","\n","    row_padding = padded_rows - lr_rows\n","    col_padding = padded_cols - lr_cols\n","\n","    scaling_factor = padded_scaled_image.shape[0] // padded_rows\n","\n","    extract_from_row = int(row_padding / 2 * scaling_factor)\n","    extract_till_row = -1\n","\n","    if row_padding > 0:\n","        extract_till_row = - extract_from_row\n","\n","    extract_from_col = int(col_padding / 2 * scaling_factor)\n","    extract_till_col = -1\n","\n","    if col_padding > 0:\n","        extract_till_col = - extract_from_col\n","\n","    return padded_scaled_image[extract_from_row:extract_till_row, extract_from_col:extract_till_col]\n","\n","def process_in_patches(model, lr, patch_size, batch_size):\n","    extracted_patches = tf.image.extract_patches(images=lr,\n","                             sizes=[1, patch_size, patch_size, 1],\n","                             strides=[1, patch_size, patch_size, 1],\n","                             rates=[1, 1, 1, 1],\n","                             padding='SAME')\n","\n","    patches_per_row, patches_per_col = extracted_patches.shape[1], extracted_patches.shape[2]\n","\n","    extracted_patches = extracted_patches.numpy().reshape(-1, patch_size, patch_size, 3)\n","\n","    patch_results = []\n","\n","    for start_index in range(0, extracted_patches.shape[0], batch_size):\n","        end_index = start_index + batch_size\n","        \n","        preds = model.predict(extracted_patches[start_index: end_index])\n","        \n","        patch_results.append(preds)\n","\n","    patch_results = np.concatenate(patch_results, axis=0)\n","    patch_results = np.clip(patch_results, 0, 1)\n","    # patch_results = np.round(patch_results)\n","\n","    joined = join_patches(patch_results, patches_per_row, patches_per_col).astype(np.float32)\n","\n","    return unpad_patched_scaled_image(lr, patches_per_row, patches_per_col, patch_size, joined)\n","\n","def join_patches(patches, patches_per_row, patches_per_col):\n","    patch_rows, patch_cols, channels = patches[0].shape\n","    \n","    image_rows = patch_rows * (patches_per_row - 1) + patch_rows\n","    image_cols = patch_cols * (patches_per_col - 1) + patch_cols\n","    \n","    joined = np.zeros((image_rows, image_cols, 3))\n","    \n","    row, col = 0, 0\n","    \n","    for patch in patches:\n","        joined[row * patch_rows: (row+1) * (patch_rows), col * patch_cols: (col+1) * (patch_cols)] = patch\n","        \n","        col += 1\n","        \n","        if col >= patches_per_col:\n","            col = 0\n","            row += 1\n","            \n","    return joined\n","def process_full_image(model, lr):\n","    sr = model.predict(lr)[0]\n","    sr = tf.clip_by_value(sr, 0, 1)\n","    # sr = tf.round(sr)\n","    sr = tf.cast(sr, tf.float32)\n","    return sr\n"],"metadata":{"id":"KUjQbI98-00y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def specific_crop(x,y, hr_img, hr_crop_size, scale):\n","    hr_top = x * scale\n","    hr_left = y * scale\n","    hr_crop = hr_img[hr_top:hr_top + hr_crop_size, hr_left:hr_left + hr_crop_size]\n","    return  hr_crop"],"metadata":{"id":"vPRCPINQoHvn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gaussian_noise_layer(input_layer, std):\n","    noise = tf.random.normal(shape=tf.shape(input_layer), mean=0.0, stddev=std, dtype=tf.float32) \n","    return input_layer + noise"],"metadata":{"id":"PhKDUksjAJph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gaussian_kernel(size: int,\n","                    mean: float,\n","                    std: float,\n","                   ):\n","    \"\"\"Makes 2D gaussian Kernel for convolution.\"\"\"\n","\n","    d = tf.distributions.Normal(mean, std)\n","\n","    vals = d.prob(tf.range(start = -size, limit = size + 1, dtype = tf.float32))\n","\n","    gauss_kernel = tf.einsum('i,j->ij',\n","                                  vals,\n","                                  vals)\n","\n","    return gauss_kernel / tf.reduce_sum(gauss_kernel)"],"metadata":{"id":"2lXaRGhahqo3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dw1leNPiBaDM"},"source":["#Visualize Sample"]},{"cell_type":"markdown","source":["*   Set5\n","*   Set14\n","\n","\n"],"metadata":{"id":"uWMZnry4oEbp"}},{"cell_type":"markdown","source":["#Install .zip dataset from URL (Do not able this code)"],"metadata":{"id":"UXIhJJhL-PEC"}},{"cell_type":"code","source":["# !wget --no-check-certificate \\\n","#     https://drive.google.com/u/0/uc?export=download&confirm=y0q_&id=1h3H0Vm4yvMVVQgpJk3s0a304FTpOZGKg \\\n","#     -O /content/drive/MyDrive/Dataset/Evaluate/ds.zip\n","  "],"metadata":{"id":"AyeqAX0ufD1g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644119494484,"user_tz":-420,"elapsed":501,"user":{"displayName":"Dang Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiVIsFWNExnvgea51afsqnnkGntHaDnff4kdeMfQ=s64","userId":"18279381478995573430"}},"outputId":"a5002334-b80a-417b-c6a5-9985ac611f6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: -O: command not found\n","--2022-02-06 03:51:11--  https://drive.google.com/u/0/uc?export=download\n","Resolving drive.google.com (drive.google.com)... 108.177.127.101, 108.177.127.139, 108.177.127.138, ...\n","Connecting to drive.google.com (drive.google.com)|108.177.127.101|:443... connected.\n","HTTP request sent, awaiting response... 400 Bad Request\n","2022-02-06 03:51:12 ERROR 400: Bad Request.\n","\n"]}]},{"cell_type":"code","source":["# import requests\n","# file_url = \"https://drive.google.com/u/0/uc?export=download&confirm=y0q_&id=1h3H0Vm4yvMVVQgpJk3s0a304FTpOZGKg\"\n","# r = requests.get(file_url, stream = True)\n","# with open(\"/content/drive/MyDrive/Dataset/Evaluate/ds.zip\",\"wb\") as file:\n","#   for block in r.iter_content(chunk_size = 1024):\n","#     if block:\n","#       file.write(block)"],"metadata":{"id":"nm96hn2VKsDk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# import zipfile\n","# local_zip = '/content/drive/MyDrive/Dataset/Evaluate/Flickr2K/Flickr2K.zip'\n","# zip_ref = zipfile.ZipFile(local_zip, 'r')\n","# zip_ref.extractall('/content/drive/MyDrive/Dataset/Flick/')\n","# zip_ref.close()\n","# # local_zip = '/content/drive/MyDrive/Dataset/Evaludate/set5/SR_testing_datasets.zip'\n","# # zip_ref = zipfile.ZipFile(local_zip, 'r')\n","# # zip_ref.extractall('/content/drive/MyDrive/Dataset/Evaluate_dataset')\n","# # zip_ref.close()"],"metadata":{"id":"6JpBdkg3d34V"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"LoadingDataset.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}