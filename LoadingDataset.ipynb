{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LoadingDataset.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"nro1Ta20yNBQ"},"source":["#Introduce"]},{"cell_type":"markdown","metadata":{"id":"OahgAgoTxnpo"},"source":["This notebook is created for the case using to load the Dataset (DIV2k) with difference key, and preprocessing image:\n","\n","\n","1.   Load the dataset with key.\n","2.   Preprocessing image.\n","3.   Seperate the dataset.\n","\n"]},{"cell_type":"code","metadata":{"id":"0pJbwX-QEN5U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638348164625,"user_tz":-420,"elapsed":3630,"user":{"displayName":"Dang Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_ebPu43S-FYufh94sX5vMDPiVNwnTMr7vtvzvyA=s64","userId":"18279381478995573430"}},"outputId":"8a7685cc-57f3-41df-979c-d67cc3b1f46e"},"source":["print('import libary...')\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","  "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["import libary...\n"]}]},{"cell_type":"code","metadata":{"id":"SjXd0pQAxjPL"},"source":["def load_dataset(key='div2k',include_validate=True):\n","  print('using tensorflow_datasets to load the dataset','\\nloading dataset...')\n","  if include_validate:\n","    (train_ds, val_ds), metadata = tfds.load(\n","    key,\n","    split=['train','validation'],\n","    with_info=True,\n","    as_supervised=True,\n","   )\n","  else:\n","    (train_ds), metadata = tfds.load(\n","    key,\n","    split=['train'],\n","    with_info=True,\n","    as_supervised=True,\n","    )\n","  print(metadata)\n","  return (train_ds,val_ds),metadata"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQqAcU1aLp2k"},"source":["def normalize_img(image):\n","  print('Normalizes images: `uint8` -> `float32`')\n","  return tf.cast(image, tf.float32) /255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVN6DS_ZL8UE"},"source":["def configure_performan(ds,BUFFER_SIZE=1000,BATCH_SIZE=16):\n","  ds=ds.cache()\n","  ds=ds.shuffle(buffer_size=BUFFER_SIZE)\n","  ds=ds.batch(BATCH_SIZE)\n","  ds=ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n","  return ds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XzZ2Ftvlm8b0"},"source":["def show(image, label):\n","  plt.figure(figsize=(len(image.numpy())/80,len(image.numpy()[0])/80))\n","  plt.imshow(image)\n","  plt.title(np.array(label))\n","  plt.axis('on')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKYvmYeJ2qEz"},"source":["def visualize_augmented(original, augmented,type='lr'):\n","  # plt.figure(figsize=(len(original.numpy())/80,len(original.numpy()[0])/80))\n","  fig = plt.figure()\n","  plt.subplot(1,2,1)\n","  plt.title('Original image'+type)\n","  plt.imshow(original)\n","  plt.subplot(1,2,2)\n","  plt.title('Augmented image'+type)\n","  plt.imshow(augmented)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWaMa6FXuaVJ"},"source":["def augment(lr,hr,with_adjust=True):\n","  #get the same seed to get the same operator to both lr and hr for image when we use randomly\n","  generator= tf.random.get_global_generator()\n","  seed= generator.make_seeds(2)[0]\n","  #mean that change the pixel value by adujst it's factor\n","  if with_adjust:\n","    #low resolution augmentation\n","    lr=tf.image.stateless_random_contrast(lr,0.8,1.2,seed)\n","    lr=tf.image.stateless_random_brightness(lr,0.10,seed)\n","    lr=tf.image.stateless_random_saturation(lr,0.8,1.3,seed)\n","    #high resolution augmentation\n","    hr=tf.image.stateless_random_contrast(hr,0.8,1.2,seed)\n","    hr=tf.image.stateless_random_brightness(hr,0.10,seed)\n","    hr=tf.image.stateless_random_saturation(hr,0.8,1.3,seed)\n","  #random rotate and flip\n","  roate_factor=tf.squeeze(generator.uniform([1],minval=1,maxval=5,dtype=tf.dtypes.int32), axis=0)\n","  lr=tf.image.rot90(lr,roate_factor)\n","  lr=tf.image.stateless_random_flip_left_right(lr,seed)\n","  hr=tf.image.rot90(hr,roate_factor)\n","  hr=tf.image.stateless_random_flip_left_right(hr,seed)\n","  return lr,hr"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def random_crop(lr_img, hr_img, hr_crop_size, scale):\n","    lr_crop_size = hr_crop_size // scale\n","    lr_shape = tf.shape(lr_img)[:2]\n","    lr_top = tf.random.uniform(shape=(), maxval=lr_shape[0] - lr_crop_size + 1, dtype=tf.int32)\n","    lr_left = tf.random.uniform(shape=(), maxval=lr_shape[1] - lr_crop_size + 1, dtype=tf.int32)\n","    hr_top = lr_top * scale\n","    hr_left = lr_left * scale\n","    lr_crop = lr_img[lr_top:lr_top + lr_crop_size, lr_left:lr_left + lr_crop_size]\n","    hr_crop = hr_img[hr_top:hr_top + hr_crop_size, hr_left:hr_left + hr_crop_size]\n","    return lr_crop, hr_crop"],"metadata":{"id":"Av-dnsbTJ-hW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalizes RGB images to [-1, 1].\n","def normalize_m11(x):\n","    return x / 127.5 - 1\n","# Normalizes RGB images to [0, 1].\n","def normalize_01(x):\n","    return x / 255.0\n","# Denomalizes RGB images from [-1, 1].\n","def denormalize_m11(x):\n","    return (x + 1) * 127.5"],"metadata":{"id":"DZieOo_UQJBl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"YXuIengEQQmq"},"execution_count":null,"outputs":[]}]}